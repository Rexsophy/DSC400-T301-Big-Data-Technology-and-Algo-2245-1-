{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d41f20-322f-4a91-99f4-1e56b429251b",
   "metadata": {},
   "source": [
    "#### Rex Gayas\n",
    "#### Week 3 Exercise 3.2 Spring 2024\n",
    "#### DSC400-T301 Big Data, Technology, and Algo (2245-1)\n",
    "#### MapReduce Patterns in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1917363-dae8-4dd2-b7fb-a93ca44cef04",
   "metadata": {},
   "source": [
    "#### Assignment 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b01a0d-e781-4184-b8d7-26a50a0c93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7784b4a-6d48-4770-b275-116e55dd7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "    Well, the way they make shows is, they make one show. \n",
    "    That show's called a pilot. \n",
    "    Then they show that show to the people who make shows, \n",
    "    and on the strength of that one show they decide \n",
    "    if they're going to make more shows. Some pilots \n",
    "    get picked and become television programs. \n",
    "    Some don't, become nothing. \n",
    "    She starred in one of the ones that became nothing.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "    You think water moves fast? You should see ice. \n",
    "    It moves like it has a mind. \n",
    "    Like it knows it killed the world once and got a taste for murder. \n",
    "    After the avalanche, it took us a week to climb out. \n",
    "    Now, I don't know exactly when we turned on each other, \n",
    "    but I know that seven of us survived the slide... \n",
    "    and only five made it out. Now we took an oath, that I'm breaking now. \n",
    "    We said we'd say it was the snow that killed the other two, but it wasn't. \n",
    "    Nature is lethal but it doesn't hold a candle to man.\n",
    "\"\"\"\n",
    "\n",
    "text3 = \"\"\"\n",
    "    Now that we know who you are, I know who I am. I'm not a mistake! \n",
    "    It all makes sense! In a comic, you know how you can tell who the arch-villain's going to be? \n",
    "    He's the exact opposite of the hero. And most times they're friends, like you and me! \n",
    "    I should've known way back when... You know why, David? Because of the kids. \n",
    "    They called me Mr Glass.\n",
    "\"\"\"\n",
    "\n",
    "text4 = \"\"\"\n",
    "    Your bones don't break, mine do. That's clear. \n",
    "    Your cells react to bacteria and viruses differently than mine. \n",
    "    You don't get sick, I do. That's also clear. \n",
    "    But for some reason, you and I react the exact same way to water. \n",
    "    We swallow it too fast, we choke. We get some in our lungs, we drown. \n",
    "    However unreal it may seem, we are connected, you and I. \n",
    "    We're on the same curve, just on opposite ends.\n",
    "\"\"\"\n",
    "\n",
    "documents = [text1, text2, text3, text4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc127226-ead7-41c5-8b78-27af4a96b6b4",
   "metadata": {},
   "source": [
    "#### Assignment 3.1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6833d8a9-897a-4c84-96b0-3394b6664693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple function to remove punctuation from text\n",
    "    :param text: text to remove punctuation from\n",
    "    :return: text with punctuation removed\n",
    "    \"\"\"\n",
    "    return ''.join([\n",
    "        character\n",
    "        for character in text\n",
    "        if character not in string.punctuation\n",
    "    ])\n",
    "\n",
    "def word_count_map_function(text: str) -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Simple map function that takes text and outputs tuples of words and counts\n",
    "    :param text: text to convert into word/count tuples\n",
    "    :return: A list of tuples with word and count\n",
    "    \"\"\"\n",
    "    # Remove punctuation from text\n",
    "    text = remove_punctuation(text)\n",
    "    \n",
    "    # Convert text to Lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Split the text by spaces to convert into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Return a list containing a tuple for each word\n",
    "    word_count_pairs = [(word, 1) for word in words]\n",
    "    \n",
    "    return word_count_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd0406-1061-4bf6-92b7-48be1add3d12",
   "metadata": {},
   "source": [
    "Wrote a map function that processes a document and outputs word/count tuple pairs and count the occurrences of words in a collection of documents. This function will create a list of tuples, where each tuple is a word from the text paired with the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9964d46-074b-4bdb-b13f-0c7879af48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [text1, text2, text3, text4]  \n",
    "\n",
    "# Map each document using the word_count_map_function\n",
    "mapped_documents = list(map(word_count_map_function, documents))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fa107-f1eb-4651-b6b7-a608fe0970a8",
   "metadata": {},
   "source": [
    "This maps the “word_count_map_function” across all documents, returning a list of lists, with each inner list containing the word/count pairs for one document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047b451-16ae-4e8b-b32c-bb92a845b8b6",
   "metadata": {},
   "source": [
    "#### Assignment 3.1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f7cf81-2424-480f-93ad-59efd04396c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "# The remove_punctuation function from assignment 3.1a\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    return ''.join([character for character in text if character not in string.punctuation])\n",
    "\n",
    "# The word_count_map_function from assignment 3.1a\n",
    "def word_count_map_function(text: str) -> list[tuple[str, int]]:\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return [(word, 1) for word in words]\n",
    "\n",
    "# The word_count_reduce_function as required for assignment 3.1b\n",
    "def word_count_reduce_function(key_value_pairs):\n",
    "    result = dict()\n",
    "    for pair in key_value_pairs:\n",
    "        word, count = pair\n",
    "        if word in result:\n",
    "            result[word] += count\n",
    "        else:\n",
    "            result[word] = count\n",
    "    return result\n",
    "\n",
    "# List of documents\n",
    "documents = [text1, text2, text3, text4]\n",
    "\n",
    "# Step 1: Apply the `word_count_map_function` to each of the documents\n",
    "map_output_values = list(map(word_count_map_function, documents))\n",
    "\n",
    "# Flatten the list of lists into a single list of tuples\n",
    "merged_output_values = reduce(add, map_output_values)\n",
    "\n",
    "# Step 2: Apply the `word_count_reduce_function` to create a single word/count dictionary\n",
    "counted_words_dict = word_count_reduce_function(merged_output_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7f18c-9c4b-4c1e-9aac-6aae81ac363b",
   "metadata": {},
   "source": [
    "This is to demonstrate a simplified MapReduce operation in Python for processing a collection of text documents. The “word_count_map_function” tokenizes each document and maps words to a count of one, while the “word_count_reduce_function” aggregates these counts to produce a final dictionary where each word is a key, and the corresponding value is the total number of occurrences of that word across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c476c97-a04c-498d-9281-1102dc445a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map Function Output:\n",
      "[('well', 1), ('the', 1), ('way', 1), ('they', 1), ('make', 1), ('shows', 1), ('is', 1), ('they', 1), ('make', 1), ('one', 1), ('show', 1), ('that', 1), ('shows', 1), ('called', 1), ('a', 1), ('pilot', 1), ('then', 1), ('they', 1), ('show', 1), ('that', 1), ('show', 1), ('to', 1), ('the', 1), ('people', 1), ('who', 1), ('make', 1), ('shows', 1), ('and', 1), ('on', 1), ('the', 1), ('strength', 1), ('of', 1), ('that', 1), ('one', 1), ('show', 1), ('they', 1), ('decide', 1), ('if', 1), ('theyre', 1), ('going', 1), ('to', 1), ('make', 1), ('more', 1), ('shows', 1), ('some', 1), ('pilots', 1), ('get', 1), ('picked', 1), ('and', 1), ('become', 1), ('television', 1), ('programs', 1), ('some', 1), ('dont', 1), ('become', 1), ('nothing', 1), ('she', 1), ('starred', 1), ('in', 1), ('one', 1), ('of', 1), ('the', 1), ('ones', 1), ('that', 1), ('became', 1), ('nothing', 1)]\n",
      "[('you', 1), ('think', 1), ('water', 1), ('moves', 1), ('fast', 1), ('you', 1), ('should', 1), ('see', 1), ('ice', 1), ('it', 1), ('moves', 1), ('like', 1), ('it', 1), ('has', 1), ('a', 1), ('mind', 1), ('like', 1), ('it', 1), ('knows', 1), ('it', 1), ('killed', 1), ('the', 1), ('world', 1), ('once', 1), ('and', 1), ('got', 1), ('a', 1), ('taste', 1), ('for', 1), ('murder', 1), ('after', 1), ('the', 1), ('avalanche', 1), ('it', 1), ('took', 1), ('us', 1), ('a', 1), ('week', 1), ('to', 1), ('climb', 1), ('out', 1), ('now', 1), ('i', 1), ('dont', 1), ('know', 1), ('exactly', 1), ('when', 1), ('we', 1), ('turned', 1), ('on', 1), ('each', 1), ('other', 1), ('but', 1), ('i', 1), ('know', 1), ('that', 1), ('seven', 1), ('of', 1), ('us', 1), ('survived', 1), ('the', 1), ('slide', 1), ('and', 1), ('only', 1), ('five', 1), ('made', 1), ('it', 1), ('out', 1), ('now', 1), ('we', 1), ('took', 1), ('an', 1), ('oath', 1), ('that', 1), ('im', 1), ('breaking', 1), ('now', 1), ('we', 1), ('said', 1), ('wed', 1), ('say', 1), ('it', 1), ('was', 1), ('the', 1), ('snow', 1), ('that', 1), ('killed', 1), ('the', 1), ('other', 1), ('two', 1), ('but', 1), ('it', 1), ('wasnt', 1), ('nature', 1), ('is', 1), ('lethal', 1), ('but', 1), ('it', 1), ('doesnt', 1), ('hold', 1), ('a', 1), ('candle', 1), ('to', 1), ('man', 1)]\n",
      "[('now', 1), ('that', 1), ('we', 1), ('know', 1), ('who', 1), ('you', 1), ('are', 1), ('i', 1), ('know', 1), ('who', 1), ('i', 1), ('am', 1), ('im', 1), ('not', 1), ('a', 1), ('mistake', 1), ('it', 1), ('all', 1), ('makes', 1), ('sense', 1), ('in', 1), ('a', 1), ('comic', 1), ('you', 1), ('know', 1), ('how', 1), ('you', 1), ('can', 1), ('tell', 1), ('who', 1), ('the', 1), ('archvillains', 1), ('going', 1), ('to', 1), ('be', 1), ('hes', 1), ('the', 1), ('exact', 1), ('opposite', 1), ('of', 1), ('the', 1), ('hero', 1), ('and', 1), ('most', 1), ('times', 1), ('theyre', 1), ('friends', 1), ('like', 1), ('you', 1), ('and', 1), ('me', 1), ('i', 1), ('shouldve', 1), ('known', 1), ('way', 1), ('back', 1), ('when', 1), ('you', 1), ('know', 1), ('why', 1), ('david', 1), ('because', 1), ('of', 1), ('the', 1), ('kids', 1), ('they', 1), ('called', 1), ('me', 1), ('mr', 1), ('glass', 1)]\n",
      "[('your', 1), ('bones', 1), ('dont', 1), ('break', 1), ('mine', 1), ('do', 1), ('thats', 1), ('clear', 1), ('your', 1), ('cells', 1), ('react', 1), ('to', 1), ('bacteria', 1), ('and', 1), ('viruses', 1), ('differently', 1), ('than', 1), ('mine', 1), ('you', 1), ('dont', 1), ('get', 1), ('sick', 1), ('i', 1), ('do', 1), ('thats', 1), ('also', 1), ('clear', 1), ('but', 1), ('for', 1), ('some', 1), ('reason', 1), ('you', 1), ('and', 1), ('i', 1), ('react', 1), ('the', 1), ('exact', 1), ('same', 1), ('way', 1), ('to', 1), ('water', 1), ('we', 1), ('swallow', 1), ('it', 1), ('too', 1), ('fast', 1), ('we', 1), ('choke', 1), ('we', 1), ('get', 1), ('some', 1), ('in', 1), ('our', 1), ('lungs', 1), ('we', 1), ('drown', 1), ('however', 1), ('unreal', 1), ('it', 1), ('may', 1), ('seem', 1), ('we', 1), ('are', 1), ('connected', 1), ('you', 1), ('and', 1), ('i', 1), ('were', 1), ('on', 1), ('the', 1), ('same', 1), ('curve', 1), ('just', 1), ('on', 1), ('opposite', 1), ('ends', 1)]\n",
      "\n",
      "Reduced Word Count Dictionary:\n",
      "{'well': 1, 'the': 15, 'way': 3, 'they': 5, 'make': 4, 'shows': 4, 'is': 2, 'one': 3, 'show': 4, 'that': 8, 'called': 2, 'a': 7, 'pilot': 1, 'then': 1, 'to': 7, 'people': 1, 'who': 4, 'and': 9, 'on': 4, 'strength': 1, 'of': 5, 'decide': 1, 'if': 1, 'theyre': 2, 'going': 2, 'more': 1, 'some': 4, 'pilots': 1, 'get': 3, 'picked': 1, 'become': 2, 'television': 1, 'programs': 1, 'dont': 4, 'nothing': 2, 'she': 1, 'starred': 1, 'in': 3, 'ones': 1, 'became': 1, 'you': 10, 'think': 1, 'water': 2, 'moves': 2, 'fast': 2, 'should': 1, 'see': 1, 'ice': 1, 'it': 12, 'like': 3, 'has': 1, 'mind': 1, 'knows': 1, 'killed': 2, 'world': 1, 'once': 1, 'got': 1, 'taste': 1, 'for': 2, 'murder': 1, 'after': 1, 'avalanche': 1, 'took': 2, 'us': 2, 'week': 1, 'climb': 1, 'out': 2, 'now': 4, 'i': 8, 'know': 6, 'exactly': 1, 'when': 2, 'we': 9, 'turned': 1, 'each': 1, 'other': 2, 'but': 4, 'seven': 1, 'survived': 1, 'slide': 1, 'only': 1, 'five': 1, 'made': 1, 'an': 1, 'oath': 1, 'im': 2, 'breaking': 1, 'said': 1, 'wed': 1, 'say': 1, 'was': 1, 'snow': 1, 'two': 1, 'wasnt': 1, 'nature': 1, 'lethal': 1, 'doesnt': 1, 'hold': 1, 'candle': 1, 'man': 1, 'are': 2, 'am': 1, 'not': 1, 'mistake': 1, 'all': 1, 'makes': 1, 'sense': 1, 'comic': 1, 'how': 1, 'can': 1, 'tell': 1, 'archvillains': 1, 'be': 1, 'hes': 1, 'exact': 2, 'opposite': 2, 'hero': 1, 'most': 1, 'times': 1, 'friends': 1, 'me': 2, 'shouldve': 1, 'known': 1, 'back': 1, 'why': 1, 'david': 1, 'because': 1, 'kids': 1, 'mr': 1, 'glass': 1, 'your': 2, 'bones': 1, 'break': 1, 'mine': 2, 'do': 2, 'thats': 2, 'clear': 2, 'cells': 1, 'react': 2, 'bacteria': 1, 'viruses': 1, 'differently': 1, 'than': 1, 'sick': 1, 'also': 1, 'reason': 1, 'same': 2, 'swallow': 1, 'too': 1, 'choke': 1, 'our': 1, 'lungs': 1, 'drown': 1, 'however': 1, 'unreal': 1, 'may': 1, 'seem': 1, 'connected': 1, 'were': 1, 'curve': 1, 'just': 1, 'ends': 1}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "# The remove_punctuation function from assignment 3.1a\n",
    "def remove_punctuation(text: str) -> str:\n",
    "    return ''.join([character for character in text if character not in string.punctuation])\n",
    "\n",
    "# The word_count_map_function from assignment 3.1a\n",
    "def word_count_map_function(text: str) -> list[tuple[str, int]]:\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return [(word, 1) for word in words]\n",
    "\n",
    "# The word_count_reduce_function as required for assignment 3.1b\n",
    "def word_count_reduce_function(key_value_pairs):\n",
    "    result = dict()\n",
    "    for pair in key_value_pairs:\n",
    "        word, count = pair\n",
    "        if word in result:\n",
    "            result[word] += count\n",
    "        else:\n",
    "            result[word] = count\n",
    "    return result\n",
    "\n",
    "# List of documents\n",
    "documents = [text1, text2, text3, text4]\n",
    "\n",
    "# Apply the map function to each document\n",
    "map_output_values = list(map(word_count_map_function, documents))\n",
    "\n",
    "# Print the output of the map function\n",
    "print(\"Map Function Output:\")\n",
    "for map_output in map_output_values:\n",
    "    print(map_output)\n",
    "\n",
    "# Flatten the list of lists into a single list of tuples\n",
    "merged_output_values = reduce(add, map_output_values)\n",
    "\n",
    "# Apply the word_count_reduce_function to create a single word/count dictionary\n",
    "counted_words_dict = word_count_reduce_function(merged_output_values)\n",
    "\n",
    "# Print the final word count dictionary\n",
    "print(\"\\nReduced Word Count Dictionary:\")\n",
    "print(counted_words_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c16a6-0a10-498f-801d-758b1a215f3a",
   "metadata": {},
   "source": [
    "The MapReduce-like workflow is shown by first mapping each word in a set of documents to a preliminary count and then reducing these counts to compile a comprehensive tally of word frequencies. Print statements have been provided to output the intermediate and final results to help demonstrate each step in the MapReduce process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead276b-e1fe-4e8f-857a-edc193ac9e6b",
   "metadata": {},
   "source": [
    "#### Assignment 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11dc1c6-9ed4-49cf-9dd4-88d600d8c709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('of', 5), ('water', 2), ('like', 3), ('once', 1), ('out', 2), ('now', 4), ('i', 8), ('exactly', 1), ('when', 2), ('other', 2), ('but', 4), ('an', 1), ('oath', 1), ('im', 2), ('two', 1), ('are', 2), ('why', 1), ('bones', 1), ('choke', 1), ('however', 1), ('ends', 1), ('show', 4), ('that', 8), ('a', 7), ('pilot', 1), ('then', 1), ('who', 4), ('starred', 1), ('became', 1), ('you', 10), ('has', 1), ('knows', 1), ('breaking', 1), ('snow', 1), ('nature', 1), ('hold', 1), ('makes', 1), ('how', 1), ('david', 1), ('break', 1), ('swallow', 1), ('drown', 1), ('seem', 1), ('strength', 1), ('theyre', 2), ('television', 1), ('programs', 1), ('moves', 2), ('murder', 1), ('we', 9), ('seven', 1), ('said', 1), ('wed', 1), ('am', 1), ('clear', 2), ('than', 1), ('just', 1), ('well', 1), ('called', 2), ('going', 2), ('pilots', 1), ('get', 3), ('she', 1), ('fast', 2), ('it', 12), ('for', 2), ('survived', 1), ('made', 1), ('doesnt', 1), ('times', 1), ('because', 1), ('kids', 1), ('your', 2), ('react', 2), ('bacteria', 1), ('viruses', 1), ('also', 1), ('too', 1), ('our', 1), ('connected', 1), ('become', 2), ('in', 3), ('think', 1), ('mind', 1), ('killed', 2), ('got', 1), ('us', 2), ('climb', 1), ('only', 1), ('say', 1), ('was', 1), ('wasnt', 1), ('mistake', 1), ('tell', 1), ('archvillains', 1), ('hes', 1), ('known', 1), ('glass', 1), ('do', 2), ('cells', 1), ('may', 1), ('the', 15), ('shows', 4), ('to', 7), ('people', 1), ('and', 9), ('nothing', 2), ('should', 1), ('each', 1), ('man', 1), ('be', 1), ('opposite', 2), ('most', 1), ('differently', 1), ('reason', 1), ('way', 3), ('make', 4), ('is', 2), ('more', 1), ('picked', 1), ('ice', 1), ('world', 1), ('after', 1), ('avalanche', 1), ('took', 2), ('week', 1), ('know', 6), ('turned', 1), ('slide', 1), ('comic', 1), ('hero', 1), ('shouldve', 1), ('mr', 1), ('lungs', 1), ('unreal', 1), ('curve', 1), ('they', 5), ('one', 3), ('on', 4), ('decide', 1), ('if', 1), ('some', 4), ('dont', 4), ('ones', 1), ('see', 1), ('taste', 1), ('five', 1), ('lethal', 1), ('candle', 1), ('not', 1), ('all', 1), ('sense', 1), ('can', 1), ('exact', 2), ('friends', 1), ('me', 2), ('back', 1), ('mine', 2), ('thats', 2), ('sick', 1), ('same', 2), ('were', 1)]\n",
      "[('of', 5), ('i', 8), ('that', 8), ('a', 7), ('you', 10), ('we', 9), ('it', 12), ('the', 15), ('to', 7), ('and', 9), ('know', 6), ('they', 5)]\n",
      "[('the', 15), ('it', 12), ('you', 10), ('we', 9), ('and', 9), ('i', 8), ('that', 8), ('a', 7), ('to', 7), ('know', 6), ('of', 5), ('they', 5), ('now', 4), ('but', 4), ('show', 4), ('who', 4), ('shows', 4), ('make', 4), ('on', 4), ('some', 4), ('dont', 4), ('like', 3), ('get', 3), ('in', 3), ('way', 3), ('one', 3), ('water', 2), ('out', 2), ('when', 2), ('other', 2), ('im', 2), ('are', 2), ('theyre', 2), ('moves', 2), ('clear', 2), ('called', 2), ('going', 2), ('fast', 2), ('for', 2), ('your', 2), ('react', 2), ('become', 2), ('killed', 2), ('us', 2), ('do', 2), ('nothing', 2), ('opposite', 2), ('is', 2), ('took', 2), ('exact', 2), ('me', 2), ('mine', 2), ('thats', 2), ('same', 2), ('once', 1), ('exactly', 1), ('an', 1), ('oath', 1), ('two', 1), ('why', 1), ('bones', 1), ('choke', 1), ('however', 1), ('ends', 1), ('pilot', 1), ('then', 1), ('starred', 1), ('became', 1), ('has', 1), ('knows', 1), ('breaking', 1), ('snow', 1), ('nature', 1), ('hold', 1), ('makes', 1), ('how', 1), ('david', 1), ('break', 1), ('swallow', 1), ('drown', 1), ('seem', 1), ('strength', 1), ('television', 1), ('programs', 1), ('murder', 1), ('seven', 1), ('said', 1), ('wed', 1), ('am', 1), ('than', 1), ('just', 1), ('well', 1), ('pilots', 1), ('she', 1), ('survived', 1), ('made', 1), ('doesnt', 1), ('times', 1), ('because', 1), ('kids', 1), ('bacteria', 1), ('viruses', 1), ('also', 1), ('too', 1), ('our', 1), ('connected', 1), ('think', 1), ('mind', 1), ('got', 1), ('climb', 1), ('only', 1), ('say', 1), ('was', 1), ('wasnt', 1), ('mistake', 1), ('tell', 1), ('archvillains', 1), ('hes', 1), ('known', 1), ('glass', 1), ('cells', 1), ('may', 1), ('people', 1), ('should', 1), ('each', 1), ('man', 1), ('be', 1), ('most', 1), ('differently', 1), ('reason', 1), ('more', 1), ('picked', 1), ('ice', 1), ('world', 1), ('after', 1), ('avalanche', 1), ('week', 1), ('turned', 1), ('slide', 1), ('comic', 1), ('hero', 1), ('shouldve', 1), ('mr', 1), ('lungs', 1), ('unreal', 1), ('curve', 1), ('decide', 1), ('if', 1), ('ones', 1), ('see', 1), ('taste', 1), ('five', 1), ('lethal', 1), ('candle', 1), ('not', 1), ('all', 1), ('sense', 1), ('can', 1), ('friends', 1), ('back', 1), ('sick', 1), ('were', 1)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "\n",
    "# Initialize Spark Session and Spark Context\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DSC 400 Assignment 3\") \\\n",
    "    .getOrCreate()\n",
    "spark_context = spark.sparkContext\n",
    "\n",
    "# Create an RDD from the documents\n",
    "documents_rdd = spark_context.parallelize(documents)\n",
    "\n",
    "# Use flatMap and reduceByKey for MapReduce tasks\n",
    "map_output_rdd = documents_rdd.flatMap(word_count_map_function)\n",
    "word_count_rdd = map_output_rdd.reduceByKey(add)\n",
    "\n",
    "# Collect the results to the driver program\n",
    "word_count_collect = word_count_rdd.collect()\n",
    "print(word_count_collect)\n",
    "\n",
    "# Filter out the word count pairs where the count is greater than four\n",
    "counts_gt_four_rdd = word_count_rdd.filter(lambda x: x[1] > 4)\n",
    "\n",
    "# Collect the filtered results to the driver program\n",
    "counts_gt_four_collect = counts_gt_four_rdd.collect()\n",
    "print(counts_gt_four_collect)\n",
    "\n",
    "# Sort the entries by their count values in descending order\n",
    "sorted_word_count_rdd = word_count_rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "# Collect the sorted results to the driver program\n",
    "sorted_word_count_collect = sorted_word_count_rdd.collect()\n",
    "print(sorted_word_count_collect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864ef4d-db64-478b-82b7-f720b01d5502",
   "metadata": {},
   "source": [
    "Created a Resilient Distributed Dataset (RDD) from a list of documents for parallel processing which applies a MapReduce pattern to perform a word count using flatMap and reduceByKey, with the output being a collection of word-count pairs. Subsequently, the word-count pairs were filtered to keep only those with counts greater than four and the resulting pairs were sorted in descending order by count. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b3635-3406-4e12-ba70-e3926e0b1f02",
   "metadata": {},
   "source": [
    "#### Assignment 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9387196-6fc9-4ca3-84e4-1084c709ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n",
      "+-------+-----+\n",
      "|   word|count|\n",
      "+-------+-----+\n",
      "|     of|    5|\n",
      "|  water|    2|\n",
      "|   like|    3|\n",
      "|   once|    1|\n",
      "|    out|    2|\n",
      "|    now|    4|\n",
      "|      i|    8|\n",
      "|exactly|    1|\n",
      "|   when|    2|\n",
      "|  other|    2|\n",
      "|    but|    4|\n",
      "|     an|    1|\n",
      "|   oath|    1|\n",
      "|     im|    2|\n",
      "|    two|    1|\n",
      "|    are|    2|\n",
      "|    why|    1|\n",
      "|  bones|    1|\n",
      "|  choke|    1|\n",
      "|however|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|  of|    5|\n",
      "|   i|    8|\n",
      "|that|    8|\n",
      "|   a|    7|\n",
      "| you|   10|\n",
      "|  we|    9|\n",
      "|  it|   12|\n",
      "| the|   15|\n",
      "|  to|    7|\n",
      "| and|    9|\n",
      "|know|    6|\n",
      "|they|    5|\n",
      "+----+-----+\n",
      "\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|   15|\n",
      "|  it|   12|\n",
      "| you|   10|\n",
      "|  we|    9|\n",
      "| and|    9|\n",
      "|   i|    8|\n",
      "|that|    8|\n",
      "|  to|    7|\n",
      "|   a|    7|\n",
      "|know|    6|\n",
      "|  of|    5|\n",
      "|they|    5|\n",
      "+----+-----+\n",
      "\n",
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|   15|\n",
      "|  it|   12|\n",
      "| you|   10|\n",
      "| and|    9|\n",
      "|  we|    9|\n",
      "|   i|    8|\n",
      "|that|    8|\n",
      "|  to|    7|\n",
      "|   a|    7|\n",
      "|know|    6|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"DSC 400 Assignment 3\").getOrCreate()\n",
    "\n",
    "# Spark DataFrame from the word_count_rdd previously defined\n",
    "word_count_columns = [\"word\", \"count\"]\n",
    "word_count_df = spark.createDataFrame(data=word_count_rdd, schema=word_count_columns)\n",
    "\n",
    "# Print the DataFrame schema\n",
    "word_count_df.printSchema()\n",
    "\n",
    "# Show the DataFrame as a table\n",
    "word_count_df.show()\n",
    "\n",
    "# Assignment 3.3.a: Filter to create a new DataFrame with word counts greater than four\n",
    "word_count_filtered = word_count_df.filter(col(\"count\") > 4)\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "word_count_filtered.show()\n",
    "\n",
    "# Assignment 3.3.b: Create a new DataFrame sorted by word count in descending order\n",
    "word_count_sorted = word_count_filtered.sort(col(\"count\").desc())\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "word_count_sorted.show()\n",
    "\n",
    "# Assignment 3.3.c: Create a new DataFrame that contains the top ten word count values\n",
    "word_count_top_10 = word_count_sorted.limit(10)\n",
    "\n",
    "# Show the DataFrame with the top ten word counts\n",
    "word_count_top_10.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37468f-fb20-48a1-88c4-a663a85aec94",
   "metadata": {},
   "source": [
    "Created a data frame from an existing RDD, which provided a structured view with a defined schema for word counts. Then, this data frame was filtered to retain only those records where the word count exceeds four, then the results were sorted in descending order to prioritize higher word counts, and finally the top ten-word counts were extracted. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
